# Training Configuration for SDXL DreamBooth with PEFT Adapters

# Base model used for training initialization
pretrained_model_name_or_path: "stabilityai/stable-diffusion-xl-base-1.0"

# Training parameters
max_train_steps: 500
learning_rate: 1e-4
text_encoder_lr: 5e-5
adam_weight_decay: 1e-4
adam_weight_decay_text_encoder: 1e-4
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 1e-8
max_grad_norm: 1.0
gradient_accumulation_steps: 4
train_batch_size: 1
resolution: 1024
lr_warmup_steps: 0
lr_num_cycles: 1
prior_loss_weight: 1.0  # Only used with prior preservation

# Optimization settings
use_8bit_adam: false
use_gradient_checkpointing: true
enable_xformers_memory_efficient_attention: true
mixed_precision: "fp16"  # Can be "no", "fp16", or "bf16"

# Text encoder training settings
train_text_encoder: false
with_prior_preservation: false

# Checkpointing settings
checkpointing_steps: 500
checkpoints_total_limit: 2
logging_steps: 10
save_steps: 200
validation_steps: 100
save_safetensors: true
symlink_best_model: true

# Dataset settings (Placeholders, often overridden by scripts)
instance_data_dir: "placeholder_path/to/instance_images" # Example: dataset/dog
instance_prompt: "a photo of [unique_token] [class_name]" # Template, replace [unique_token] and [class_name]
class_name: "placeholder_class" # Example: dog
class_prompt: "a photo of [class_name]" # Optional, for prior preservation
class_data_dir: null # Optional, directory for class images
num_class_images: 0 # Optional, number of class images to use
unique_token: "zjw" # Unique token placeholder (can be set here or experiment config)

# Image/Dataset Processing
center_crop: false
use_captions: false
caption_extension: ".txt"
repeats: 1
dataloader_num_workers: 0
shuffle: true

# Memory tracking for debugging
measure_memory_usage: false

# Prodigy optimizer settings (if used)
prodigy_beta3: null  # If null, uses sqrt(beta2)
prodigy_decouple: true  # Use AdamW style decoupled weight decay
prodigy_use_bias_correction: true  # Turn on Adam's bias correction
prodigy_safeguard_warmup: true  # Remove lr from denominator during warmup

# Learning rate scheduler
lr_scheduler: "constant"  # Options: "constant", "linear", "cosine", "cosine_with_restarts", "polynomial"
lr_power: 1.0  # For polynomial scheduler

# Diffusion loss settings
snr_gamma: null  # Set to a value like 5.0 to enable min-SNR weighting

# Validation
validation_prompt: null
num_validation_images: 4

# Output directory (Base directory for training runs)
output_dir: "output/sdxl_dreambooth"

# Seed for training reproducibility
seed: 42 